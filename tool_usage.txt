## Fastqc v0.11.9
# Fastqc used on both FASTQ and BAM files

for i in *fastq.gz; do fastqc $i -t 8 -o <out_dir> ; done

for i in *.bam; do fastqc $i -t 8 -o <out_dir> ; done

## Samtools v1.9

# Remove duplicates
for i in *.bam; do samtools fixmate -m -@ 4 ${i} - |  samtools markdup -r -l 100 -s -@ 8 - mrkdup_${i}; done

# Index
for i in *.bam; do samtools index -@ 8 $i; done

# Print counts by chromosome
samtools idxstats in.bam | awk '{print $1" "$3}'

# Remove non-canonical chromosomes
for i in *.bam; do samtools view -b -@ 8 $i chr{1..19} chrX chrY > chr_${i} ; done

## JuncBASE
# JuncBASE was run as described in the manual using the `by_chr` options wherever possible.
# The same commands were used for both CS/RA samples and LPS-CS/LPS-RA samples.
# The previous command run with `--check` was run wherever possible, ommitted here for space.
# SQLite databases were constructed from custom GTF, intron input was from Gencode vM18.
# The output <out> of the current step is generally the input <in> of the subsequent step

python run_preProcess_by_chr_step1.py \
	-i <in> -o <out> \
	--preProcess_options "â€“unique -j ../annotations/M18_introns.txt" -p 20

# Remove non canonical chromosomes
rm -R chr_*/*random
rm -R chr_*/*chrU*

python disambiguate_junctions.py -i <in> -g ../annotations/GRCm38.primary_assembly.genome.fa  --by_chr --majority_rules

python preProcess_getASEventReadCounts_by_chr_step2.py -i <in> --by_chr

python run_preProcess_step3_by_chr.py --input_dir <in> --num_processes 20

python createPseudoSample.py -i <in> -s <single_sample> --by_chr

python run_getASEventReadCounts_multiSample.py -s <samples> \
-i <in> -o <out> --sqlite_db_dir ../juncBASE_DBs/ --txt_db1 <custom_gtf> --txt_db2 <custom_gtf> --txt_db3 <custom_gtf> --jcn_seq_len 188 -p 20 --by_chr

python run_createAS_CountTables.py -d <out> -i <in> --jcn_seq_len 188 -s <samples> --num_processes 20

python combine_createAS_CountTables_by_chr.py -d <in> -o <out>

python compareSampleSets.py --in_prefix <in/prefix> --all_psi_output <out> \
--mt_correction BH --which_test t-test --sample_set1 <control_samples> --sample_set2 <exp_samples>

## Converstion to DRIMSeq input
# script found in Brooks dry lab protocols

jbToDRIMM.py -i JBoutput_AS_exclusion_inclusion_counts_lenNorm.txt > JBoutput_AS_exclusion_inclusion_counts_lenNorm.drimformat.txt

## DRIMSeq v1.20
# Full script is in github repo

## rMATS v4.1.1
# The same commands were used for both CS/RA samples and LPS-CS/LPS-RA samples.

rmats_turbo_v4_1_1/rmats.py \
--b1 <samples1.txt> --b2 <samples2.txt> \
--nthread 4 -t paired --readLength 100 \
--gtf <custom.gtf> --od <out> \
--libType fr-unstranded --allow-clipping

## rmats2sashimiplot v2.0.4

python3 rmats2sashimiplot/rmats2sashimiplot.py \
        --b1 <control_samples> --b2 <exp_samples> \
        -t RI -e <rMATS_IR.txt> --l1 RA --l2 CS \
        --exon_s 1 --intron_s 1 -o <out_dir>

## Custom script in Conversion of AS output to BED format
# in github repo

python SpliceResultsToBed.py -p rmats -e RI -i <rmats_intron_retention_events.txt> | sort -k1,1V -k2,2n -k3,3n

python SpliceResultsToBed.py -p drimseq -e RI -i <drim_intron_retention.tsv> --known | sort -k1,1V -k2,2n -k3,3n

## Bedtools intersect v2.27.1
# Requires 85% reciprocal (-f 0.85 -r) overlap between potential retained introns

bedtools intersect -wa -u -f -r 0.85 -a <rmatsIR.bed> -b <drimIR.bed> | wc -l

## Count entries FDR <= 0.1 from DRIMSeq output
for i in * ; do echo $i && awk '$6 <= 0.1' $i | grep ";*;" | wc -l; done
